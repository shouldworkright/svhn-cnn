ITERATION 1:

model = models.Sequential(
    [
        layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', input_shape=(32, 32, 3)),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),
        layers.Dropout(0.2),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)),
        layers.Dropout(0.3),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)),
        layers.Dropout(0.4),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(10, activation='softmax')        
    ]
)

RESULTS:

Epoch 1/15
229/229 [==============================] - 663s 3s/step - loss: 3.4966 - accuracy: 0.1776 - val_loss: 2.2551 - val_accuracy: 0.1867
Epoch 2/15
229/229 [==============================] - ETA: 0s - loss: 2.1076 - accuracy: 0.2374
Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
229/229 [==============================] - 618s 3s/step - loss: 2.1076 - accuracy: 0.2374 - val_loss: 2.2907 - val_accuracy: 0.1482
Epoch 3/15
229/229 [==============================] - 854s 4s/step - loss: 1.5161 - accuracy: 0.4901 - val_loss: 1.5665 - val_accuracy: 0.5008
Epoch 4/15
229/229 [==============================] - 851s 4s/step - loss: 0.9483 - accuracy: 0.7150 - val_loss: 0.8677 - val_accuracy: 0.7556
Epoch 5/15
229/229 [==============================] - 810s 4s/step - loss: 0.6777 - accuracy: 0.8023 - val_loss: 0.6021 - val_accuracy: 0.8241
Epoch 6/15
229/229 [==============================] - 683s 3s/step - loss: 0.5599 - accuracy: 0.8372 - val_loss: 0.5411 - val_accuracy: 0.8453
Epoch 7/15
229/229 [==============================] - 843s 4s/step - loss: 0.4947 - accuracy: 0.8534 - val_loss: 0.4892 - val_accuracy: 0.8564
Epoch 8/15
229/229 [==============================] - 855s 4s/step - loss: 0.4367 - accuracy: 0.8725 - val_loss: 0.4576 - val_accuracy: 0.8632
Epoch 9/15
229/229 [==============================] - 932s 4s/step - loss: 0.3962 - accuracy: 0.8835 - val_loss: 0.3722 - val_accuracy: 0.8909
Epoch 10/15
229/229 [==============================] - 907s 4s/step - loss: 0.3640 - accuracy: 0.8928 - val_loss: 0.3700 - val_accuracy: 0.8911
Epoch 11/15
229/229 [==============================] - 825s 4s/step - loss: 0.3347 - accuracy: 0.9019 - val_loss: 0.3643 - val_accuracy: 0.8932
Epoch 12/15
229/229 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.9074
Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
229/229 [==============================] - 795s 3s/step - loss: 0.3127 - accuracy: 0.9074 - val_loss: 0.3675 - val_accuracy: 0.8898
Epoch 13/15
229/229 [==============================] - 786s 3s/step - loss: 0.2675 - accuracy: 0.9231 - val_loss: 0.2898 - val_accuracy: 0.9172
Epoch 14/15
229/229 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9262
Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
229/229 [==============================] - 788s 3s/step - loss: 0.2562 - accuracy: 0.9262 - val_loss: 0.3080 - val_accuracy: 0.9079
Epoch 15/15
229/229 [==============================] - 721s 3s/step - loss: 0.2301 - accuracy: 0.9333 - val_loss: 0.2760 - val_accuracy: 0.9204

----------

ITERATION 2:

train_datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

(altered model)

RESULTS:
